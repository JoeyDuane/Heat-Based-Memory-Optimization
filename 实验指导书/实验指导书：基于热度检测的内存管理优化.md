# 实验指导书：基于热度检测的内存管理优化



## 一、实验原理与背景

### (1） 实验原理

#### 1. 段页式内存管理

段页式内存管理（Segmented Paging）是现代操作系统中常用的一种内存管理技术，它结合了段式内存管理和页式内存管理的优点。该方式通过将进程的虚拟地址空间分为多个段，每个段代表进程的不同功能区域，如代码段、数据段、堆栈段等。每个段可以具有不同的大小，满足程序内存需求的灵活性。

在每个段内，内存又被进一步划分为若干固定大小的**页**。页的大小通常较小，这使得内存管理能够更高效地利用内存空间。段页式管理将虚拟内存的管理分为两级：第一级是对每个段进行管理，第二级则是对每个段内的页进行管理。这样既提供了灵活的内存管理机制，也避免了内存碎片问题，并能高效地进行内存分配和回收。

段页式内存管理不仅提高了内存分配的灵活性，而且在操作系统中提供了对进程内存空间的更精细控制，使得程序的执行更加高效。它常用于现代操作系统中，因为它能够有效支持虚拟存储、进程隔离以及内存共享等机制。



#### 2. 热度检测技术

**热度检测技术**主要用于监控和分析内存的访问模式，识别内存页面的访问频率（即热度）。通过这种技术，操作系统能够准确区分哪些内存页面是频繁被访问的（热页面），哪些是很少被访问的（冷页面）。在现代操作系统中，内存访问局部性（locality of reference）是一个关键特性，即程序往往倾向于频繁访问一部分内存区域。

当系统监测到内存访问行为时，它会通过捕获**缺页中断**（hint page fault）来获取内存访问数据。缺页中断是当进程访问一个尚未映射到物理内存的虚拟页面时，触发的一个事件。操作系统通过这个事件能够不仅仅识别出缺失的页面，还能够根据访问模式和频率记录哪些页面是“热的”或“冷的”。

#### hint page fault

在段页式内存管理中，当进程尝试访问一个尚未加载到物理内存的页面时，操作系统会触发缺页中断。这时，操作系统不仅需要加载缺失的页面，还可以通过设置特殊的页面表项（PTE）权限位来捕获关于内存访问的信息。通过记录每次触发缺页中断的访问情况，操作系统能够计算出哪些页面被频繁访问，从而识别出热页面与冷页面。

这一机制使得操作系统不仅能够响应内存缺失请求，还能够进行内存访问模式分析，识别出系统中最常用的页面。对于这些热页面，操作系统可以选择将其优先存储到更快的内存区域（如高带宽的DRAM中），从而降低访问延迟，提高系统的整体性能。而冷页面则可以迁移到性能较低的内存（如NVM或交换空间）中，以优化内存的使用效率。



#### 3. NUMA（非一致性内存访问）架构

NUMA（Non-Uniform Memory Access）是一种多处理器架构，在这种架构中，每个处理器不仅拥有本地内存，还可以访问远程处理器的内存，但远程内存访问的速度较慢。NUMA架构旨在通过每个处理器拥有本地内存来提高处理器的计算能力，同时降低对远程内存的依赖。

在NUMA架构中，内存访问的性能受到很大影响：处理器访问本地内存的速度远高于访问远程内存。为此，内存的分布和访问策略需要优化，以充分发挥NUMA架构的优势，减少内存访问的延迟和吞吐量瓶颈。

本实验通过结合热度检测技术，提出了一种新的内存优化策略：动态内存分布与迁移。系统通过实时监控和分析内存访问行为，识别出哪些页面是热页面，并将这些页面优先存放在本地内存中，而冷页面则可以迁移到远程内存或较低速的存储区域。这种优化能够有效降低内存访问的延迟，提升NUMA架构下的内存访问效率。

通过热度检测技术，操作系统能够智能地调整内存页面的分布，并减少跨节点的内存访问，从而优化NUMA系统的内存共享和访问效率。优化后的系统不仅能够提升程序运行的性能，还能更好地支持高并发和大规模计算场景，特别是在多核处理器和分布式计算环境下，内存访问的优化显得尤为重要。



### （2）实验背景

本实验建立在操作系统课程中内存管理基础实验之上，深入探讨如何基于热度检测技术优化内存共享机制。在操作系统的实验课程中，内存管理基础实验的目的在于学习并实现操作系统的内存管理基础知识，包括分段与分页机制以及地址映射与共享等理论知识，掌握虚拟内存的基本概念和管理方式，通过程序模拟了对内存的分配、回收以及使用页面替换算法进行分页管理等操作。

通过前置的基础实验，学生可以了解操作系统中内存的基本管理机制，这为深入进行更为复杂的内存优化打下了基础。因此，我们希望基于内存管理基础实验进行拓展和优化创新，通过引入热度检测技术来优化内存管理的相关机制，提高内存性能。其中，热度检测技术通过追踪内存密集型应用的内存访问请求情况，识别热数据和冷数据，并根据这些信息动态调整内存布局，根据内存访问局域性在异构内存系统上实现高效的数据分布和迁移，以提高内存的访问效率。



## 二、代码实现指导

此实验需要实现的内存热度感知方案设计涉及多个核心机制，包括页面扫描、热度信息记录与识别、以及页面的迁移操作。以下是实现这些功能操作方法的相关指导。

#### （1） 物理页面扫描机制

通过扫描物理页面，对内存中的每个页面进行标记，从而捕获内存访问信息。在实现物理页面扫描时，我们首先需要明确两点：

1. **扩展 `struct page`**：为了跟踪页面的访问情况，我们需要在内核中的 `struct page` 数据结构上进行扩展。由于 `struct page` 已经包含了有关页面的重要信息（如页面所在的内存节点、是否已加载到内存等），但它并没有足够的空间来存储热度相关的元数据。因此，我们需要通过 `struct page_ext` 来扩展 `struct page`，并在其中添加时间戳、热度标志位等信息。
2. **扫描机制**：物理页面扫描的基本操作是遍历内存中所有页面，通过检查每个页面的访问标记来更新其状态。在扫描过程中，核心的操作是根据页面的热度判断该页面是否为“热页面”或“冷页面”。热页面通常是频繁访问的页面，冷页面则是长时间没有被访问的页面。

扫描过程一般包括以下步骤：

- 遍历每个内存节点，扫描节点内的所有物理页面。

- 对每个页面检查其对应的 `struct page_ext` 中的时间戳，决定该页面是热页面还是冷页面。

- 如果是热页面，则尝试将其提升到更快速的内存位置（如本地DRAM）。

- 如果是冷页面，则考虑将其迁移到较慢的内存区域（如PM或远程内存）。

  

#### （2） 热度信息记录机制

为了有效管理内存，我们需要为每个页面记录其访问历史，以便后续识别冷热页面。这可以通过在每个物理页面的 `struct page_ext` 结构中增加一个时间戳字段来实现。该时间戳字段用于记录每次页面被访问时的时间。

需要实现的操作内容如下：

- 每当页面被访问时，系统会更新该页面的时间戳。时间戳表示页面的最后一次访问时间。
- 对于标记状态的页面，时间戳表示页面被标记的时间，用于跟踪该页面是否长期未被访问。
- 对于页面的迁移操作（例如从远程内存迁移到本地内存），时间戳信息可帮助判断页面是否属于热页面。

通过不断更新页面的时间戳，操作系统可以根据时间戳的间隔来判断页面是否为热页面或冷页面。当时间戳显示页面长时间没有被访问时，可以判定该页面为冷页面，从而采取相应的迁移策略。



#### （3） 冷热页面识别机制

冷热页面的识别方法主要依赖于页面的访问时间戳等信息识别页面的冷热状态，进而决定是否对其进行迁移操作。具体的操作步骤如下：

1. **热页面识别**：
   - 通过定期扫描页面访问记录和时间戳，系统可以判断某个页面是否为热页面。如果页面的时间戳显示页面频繁被访问（即时间间隔较短），则该页面被标记为热页面。
   - 热页面通常被迁移到速度更快的内存区域（如本地DRAM），以减少访问延迟。
2. **冷页面识别**：
   - 对于时间戳显示较长时间未被访问的页面（即时间间隔较长），系统将该页面标记为冷页面。
   - 冷页面通常需要迁移到速度较慢的内存区域（如PM或远程内存节点）。这种迁移可以减少内存压力，并腾出空间给热页面。

**优化方案**： 为了提高冷热页面识别的准确性，我们还可以采取一些优化措施：

- **动态调整冷热阈值**：根据系统负载和内存使用情况，动态调整判定页面冷热状态的阈值。例如，在内存压力较大的情况下，减少判定页面为热页面的时间阈值，从而更快速地响应内存需求。
- **结合 `struct page` 中的标志位**：通过设置 `struct page` 的标志位（如 `PageUnmapLRU`），可以进一步优化冷热页面的识别过程。系统无需每次扫描 `pte`，而是直接通过标志位判断页面的冷热状态。



#### （4）页面迁移机制

**目标**：根据页面的冷热状态动态调整内存中页面的布局，优化内存访问效率。

页面迁移机制分为两种主要操作：页面提升（promote）和页面降级（demote）。通过这两种机制，可以在不同的内存区域之间移动页面，以提高整体系统性能。

1. **页面提升：
   - 当页面被标记为热页面时，需要将其迁移到更快速的内存区域，例如本地DRAM。为了实现这一点，系统需要定期检查每个页面的访问频率，如果页面被认为是热页面，则尽快将其迁移到本地内存，以降低访问延迟。
   - 页面提升的关键在于通过时间戳或访问标记来实时识别热页面。一旦识别为热页面，系统会尝试将其从远程内存节点迁移到本地内存。
2. **页面降级：
   - 对于长时间未被访问的页面（即冷页面），可以考虑将其迁移到较慢的内存区域。降级操作能够释放本地内存中的空间，为热页面腾出更多空间。
   - 冷页面的迁移操作通常发生在系统内存压力较大时。通过在 `struct page_ext` 中记录页面的访问时间，系统可以判断哪些页面长期没有被访问，并将其迁移到PM或远程内存节点。
3. **候选页面延迟迁移机制**：
   - 在内存压力非常紧张的情况下，目标内存区域可能已满，无法执行迁移操作。此时，我们设计了候选页面延迟迁移机制。当页面无法立即迁移时，系统会将其标记为候选页面，并将其加入候选队列。在内存压力减轻时，这些候选页面将会被迁移到目标内存节点。



#### （5） 性能优化与调试

在实现过程中，性能优化和调试非常关键。实验内容中希望通过以下方法，以确保系统在高负载条件下依然表现良好：

1. **性能监控**： 使用性能分析工具（如 `perf`）来监控内存访问模式，检查页面迁移操作的执行情况，确认内存访问延迟是否得到了改善。
2. **日志记录**： 在页面迁移操作中增加详细的日志记录，以便开发人员跟踪每次迁移的具体情况，分析是否需要优化。
3. **动态调整扫描频率**： 根据内存节点的负载情况动态调整页面扫描的频率。避免在低负载时进行频繁扫描，在高负载时提高扫描频率，从而实现更加灵活的内存管理。

通过这些优化方法，系统能够高效地实现内存管理，并在不同负载条件下自动调整内存资源的分配，确保系统性能的最大化。



## 三、实验测试方法

本实验旨在评估内存热度检测方案的有效性，通过对比其与现有内存管理方案（tiering-0.8 和 memtis）的性能差异。测试方法包含了环境搭建、工作负载配置、对比实验设计、以及详细的性能评估指标。具体步骤如下：

#### （1） 环境配置与准备

1. **工作负载配置**：
   - 选择了4种典型的工作负载进行性能测试，分别为Graph500、SPEC-ACCEL（404.lbm）、Redis 数据库和 GUPS。
   - 每个工作负载的内存配置与工作集大小紧密相关，以确保实验环境模拟了内存压力较大的情况。例如，对于Graph500，配置为24GB 总内存，其中DRAM与PM的容量为 4GB 和 8GB，以适配其 22.8GB 的工作集。
   - 在 Redis 测试中，构造了一个大约 19.4GB 的数据库，并通过大量读写操作来测试 Redis 的性能。
2. **内存管理方案配置**：
   - **tiering-0.8**：该方案基于 Intel AutoNUMA 技术，专注于内存动态布局。我们对其进行了一些代码修改，以便在不同内存配置下进行测试。
   - **memtis**：该方案采用 PEBS 技术，通过动态阈值优化来进行内存管理。在本实验中，考虑到我们的环境为双 socket，我们特别对 memtis 进行了调整，使用一个 socket 进行测试，并修改了内存配置来确保其性能最优化。
   - **RUNMAP**：作为本实验预期设计优化方案，RUNMAP 采用了基于页面扫描的方法，通过扫描 LRU 链表来识别内存中的热页面。为确保与 memtis 和 tiering 的可比性，我们为 RUNMAP 配置了与 memtis 相同的运行环境，并使用了 launch 程序来间接启动工作负载。



#### （2） 测试步骤与流程

1. **内核与系统配置**：
   - 通过修改内核配置并编译安装新内核，切换到适当的内核版本。使用`kexec`命令可以快速切换内核，或者通过GRUB手动选择目标内核。
   - 配置内存节点容量时，通过`memmap`参数限制每个 socket 的DRAM容量。PM的容量则通过`ndctl`工具进行设置，以确保内存容量符合实验需求。
2. **Cgroup与程序配置**：
   - 为了确保对特定进程进行内存管理，我们为 RUNMAP 和 memtis 方案配置了 Cgroup。Cgroup 允许我们精确控制和监控进程的内存使用情况，从而能够有效评估热度感知内存管理的效果。
   - 对于每个工作负载，启动前需要通过`launch`程序来确保运行环境的一致性，`launch`程序会在后台管理目标进程的 PID 信息，确保内存管理方案能够正确追踪和控制目标进程。
3. **工作负载启动与测试**：
   - 通过提前准备好的脚本自动化运行测试流程，包括运行各个工作负载的参数配置、设置内存配置、调整内核变量（如`sysctl`）等。
   - 例如，在 Graph500 测试中，我们使用Python脚本自动生成启动命令，并在Shell中运行，以便高效执行并记录实验数据。其他工作负载（如 SPEC-ACCEL 和 Redis）同样通过脚本进行控制。
4. **数据收集与日志记录**：
   - 每个工作负载在运行过程中会实时记录系统的运行日志和统计数据，包括内存使用情况、热页面扫描情况、CPU负载等信息。
   - 对于 Redis 和 GUPS 等程序，除了启动主服务进程外，还需要启动多个客户端进程来模拟并发读写操作。客户端的行为和请求模式会直接影响实验结果，因此需要精确控制客户端的数量和操作频率。
5. **实验后期处理**：
   - 在工作负载运行完成后，实验会自动保存所有运行日志和统计信息，并进行后续的数据处理。主要包括对比不同内存管理方案下的性能数据，如应用的整体运行时间、热页面迁移成功率、误判率等。



#### （3） 性能评估指标

本实验建议使用以下几个主要指标来评估内存热度检测方案的性能：

1. **整体性能**：
   - 测量各工作负载在不同内存管理方案下的总运行时间，并进行归一化处理，确保各方案的运行时间能够公平比较。
2. **扫描开销**：
   - 对比 RUNMAP 与 tiering-0.8 在热页面扫描过程中的开销。由于两者的扫描机制不同，我们分别统计了基于页面扫描的总时长与扫描到的页面数量，计算出平均扫描开销。通过比较这两者的开销，评估 RUNMAP 在保证准确度的同时是否能保持较低的开销。
3. **页面误判率**：
   - 通过已知的工作负载热数据区域，计算热页面的迁移成功率。该指标反映了内存管理方案对热页面识别和迁移的准确性，是评估方案精度的重要指标。



#### （4） 对比实验设计

为了验证 RUNMAP 方案的有效性，实验采用了与 tiering-0.8 和 memtis 的对比测试，评估在相同硬件和工作负载条件下，三者的性能差异。对比实验中的主要变量包括：

- 每个内存管理方案的配置和参数。
- 执行相同的工作负载，以确保比较结果的公平性。
- 评估指标的统一性，确保各方案测试过程中使用相同的衡量标准。

通过上述步骤，我们能够准确评估 RUNMAP 方案在不同内存压力场景下的表现，并与现有的内存管理技术进行全面对比。



## 四、实验创新点与完善性

### 1. 完善性

本实验的目标是提升传统段页式内存管理方案的性能，特别是在多核和 NUMA 架构下。通过引入热度检测技术，系统能够动态感知内存页面的访问频率，并基于此进行智能化的内存优化。与传统方法相比，本实验方案在内存分配和管理上更加灵活、智能，可以在内存压力较大时，根据页面热度信息自动优化内存布局，从而提升系统的整体性能。

具体来说，实验通过实时跟踪内存页面的访问模式，能够识别出哪些页面是“热页面”，哪些是“冷页面，并据此进行内存迁移。热页面被优先分配到性能更高的内存区域，冷页面则被迁移到较慢的存储区域。这种优化不仅能够有效减少内存访问延迟，还提高了多核和 NUMA 系统的内存共享效率，避免了不必要的内存资源浪费。

### 2. 创新点

1. **热度检测技术与内存管理结合**

   本实验的核心创新之一是将热度检测技术引入到内存管理中。传统的内存管理通常基于静态的页面分配和调度，无法动态调整内存资源分配。而通过实时检测页面的访问频率和时间，本实验能够根据内存的访问局部性自动优化内存布局，从而提高内存访问的效率和整体性能。

2. **智能内存迁移机制**

   基于热度检测结果，本实验设计了一种内存迁移机制，可以根据页面的访问频率动态迁移内存页面。热页面会优先迁移到性能更高的内存区域，而冷页面则被迁移到性能较差的区域。这一机制能够有效避免内存资源的浪费，尤其在内存紧张的情况下，有助于减少内存访问延迟，提高系统整体性能，尤其对多核系统和 NUMA 架构特别有效。

3. **基于缺页中断的动态内存优化**

   本实验利用缺页中断机制对内存进行动态优化。通过监控内存页面的访问情况，操作系统可以及时识别热页面，并在内存压力较大时，自动迁移页面或调整内存分布。此外，缺页中断还能够根据内存访问的变化动态调整内存策略，确保系统始终处于高效运行状态。

4. **跨平台适应性和可扩展性**

   该实验的优化方案不仅适用于单一节点的多核系统，还能有效支持 NUMA 系统和分布式计算环境。在 NUMA 系统中，基于热度检测的内存优化能够减少跨节点访问的开销，提高内存的共享效率。而在分布式环境下，这一方案的灵活性和可扩展性使其具有较大的应用潜力，可以支持更大规模的系统。

5. **细粒度内存访问监控**

   与传统内存管理方案不同，本实验对内存页面的访问进行了细粒度的监控。通过跟踪每个内存页面的访问历史，操作系统可以精准地识别出潜在的内存瓶颈，并根据访问模式自动调整内存分配策略。这种精细化的监控不仅有助于提升内存的利用率，还能降低系统开销，提高性能。

这些创新点有效地提升了内存管理的智能化程度和适应性，不仅优化了内存资源的分配，还增强了系统在多种硬件架构下的性能表现。